{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 星等转换为Flux单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_1176311/3363799465.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['date'][i] = t.value\n",
      "100%|██████████| 8/8 [00:00<00:00, 2360.66it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 3422.00it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 2726.23it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 3124.17it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 2901.22it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 3281.24it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 2774.14it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 3214.67it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 3399.50it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 3175.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2538.92it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 3047.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.time import Time \n",
    "namelist = ['2003MA3','2010CO1','2010DG77','2010EX11','2010FC81','2010FH81','2010GS7','2010JN71','2010KX7','2010PW58','2010XP69','2019DD2']\n",
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    rawdata = pd.read_csv(f'{name}.csv')\n",
    "    data = rawdata.loc[:,['mjd','w1mpro','w2mpro','w3mpro','w4mpro','ph_qual','sso_flg']]\n",
    "    data.insert(loc=len(data.columns),column='date',value='no')\n",
    "    #data['mjd'] = 2400000.5+data['mjd']\n",
    "    for i in tqdm(range(len(data))):  \n",
    "        t = Time(data['mjd'][i],format='mjd',scale='utc')\n",
    "        t.format = 'iso'\n",
    "        data['date'][i] = t.value\n",
    "    #data.to_csv(f'{name}.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    rawdata = pd.read_csv(f'{name}.csv')\n",
    "    data = rawdata.loc[:,['mjd','w1mpro','w2mpro','w3mpro','w4mpro','ph_qual','sso_flg']]\n",
    "    for x in data.index:\n",
    "        if data.loc[x, 'sso_flg'] ==0:\n",
    "            data.drop(x, inplace = True)\n",
    "    data.to_csv(f'New_{name}.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '2010fe7'\n",
    "rawdata = pd.read_csv(f'{name}.csv')\n",
    "data = rawdata.loc[:,['mjd','w1mpro','w2mpro','w3mpro','w4mpro','ph_qual','sso_flg']]\n",
    "for x in data.index:\n",
    "    if data.loc[x, 'sso_flg'] ==0:\n",
    "        data.drop(x, inplace = True)\n",
    "data.to_csv(f'New_{name}.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2Flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1176311/775581800.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Fc = np.array(Fc)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#-------initial para-------------------------\n",
    "#Fv0 of W1 ,W2, W3, W4\n",
    "Fv0 = [-1,306.682,170.663,29.045,8.284]\n",
    "#Color corrections  Col[Bv=1:8=(100,141,200,283,400,566,800,1131),fc=1:4=(W1,W2,W3,W4)]\n",
    "Fc0 = np.zeros((1,8))#W1,W2,W3,W4\n",
    "Fc1 = np.array([-1,17.2062,3.9096,2.6588,1.0032]) #Bv=100\n",
    "Fc2 = np.array([-1,4.0882,1.9739,1.4002,0.9852])  #Bv=141\n",
    "Fc3 = np.array([-1,2.0577,1.3448,1.0006,0.9833])  #Bv=200\n",
    "Fc4 = np.array([-1,1.3917,1.1124,0.8791,0.9865])  #Bv=283\n",
    "Fc5 = np.array([-1,1.1316,1.0229,0.8622,0.9903])  #Bv=400\n",
    "Fc6 = np.array([-1,1.0263,0.9919,0.8833,0.9935])  #Bv=566\n",
    "Fc7 = np.array([-1,0.9884,0.9853,0.9125,0.9958])  #Bv=800\n",
    "Fc8 = np.array([-1,0.9801,0.9877,0.9386,0.9975])  #Bv=1131\n",
    "Fc = [Fc0,Fc1,Fc2,Fc3,Fc4,Fc5,Fc6,Fc7,Fc8]\n",
    "Fc = np.array(Fc)\n",
    "Bv = 4\n",
    "Const = np.array([-1,Fv0[1]/Fc[Bv][1],Fv0[2]/Fc[Bv][2],Fv0[3]/Fc[Bv][3],Fv0[4]/Fc[Bv][4]])\n",
    "def h2flux(Fconst,dat_H):\n",
    "    return Fconst*np.power(10,-dat_H/2.5)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.59474707  8.90908496  7.94023033  9.44132833  7.85295485  8.17020777\n",
      "  9.06636294 71.81796595]\n"
     ]
    }
   ],
   "source": [
    "w3mag = np.array([8.962,8.923,9.048,8.86,9.06,9.017,8.904,6.657])\n",
    "print(h2flux(Const[3],w3mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------read file----------------------------\n",
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    #df = pd.read_table(f'{name}.txt')\n",
    "    df = pd.read_table(f'New_{name}.txt')\n",
    "    #data of W1,W2,W3,W4\n",
    "    dat_w1 = np.array(df['w1mpro'])\n",
    "    #dat_w1= np.hstack([dat_w1,dat_w1*0.1])\n",
    "    dat_w2 = np.array(df['w2mpro'])\n",
    "    #dat_w2= np.hstack([dat_w2,dat_w2*0.1])\n",
    "    dat_w3 = np.array(df['w3mpro'])\n",
    "    #dat_w3= np.hstack([dat_w3,dat_w3*0.1])\n",
    "    dat_w4 = np.array(df['w4mpro'])\n",
    "    #dat_w4= np.hstack([dat_w4,dat_w4*0.1])\n",
    "    #time in MJD\n",
    "    mjd =  np.array(df['mjd'])\n",
    "    #dat w1\n",
    "    dat_fluxw1 = dat_w1\n",
    "    dat_fluxw1 = Const[1]*np.power(10,-dat_w1/2.5)*1000 \n",
    "    #dat w2\n",
    "    dat_fluxw2 = dat_w2\n",
    "    dat_fluxw2 = Const[2]*np.power(10,-dat_w2/2.5)*1000 \n",
    "    #dat w3\n",
    "    dat_fluxw3 = dat_w3\n",
    "    dat_fluxw3 = Const[3]*np.power(10,-dat_w3/2.5)*1000 \n",
    "    #print(f'{Const[1]}*{np.power(10,-dat_w3[0]/2.5)}*1000={dat_fluxw3[0]}')\n",
    "    #dat w4\n",
    "    dat_fluxw4 = dat_w4\n",
    "    dat_fluxw4 = Const[4]*np.power(10,-dat_w4/2.5)*1000 \n",
    "    dat_w1w2 = np.concatenate([dat_fluxw1,dat_fluxw2],axis=0)\n",
    "    np.savetxt('w12_'+name + '.txt',dat_w1w2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '2010fe7'\n",
    "#df = pd.read_table(f'{name}.txt')\n",
    "df = pd.read_table(f'New_{name}.txt')\n",
    "#data of W1,W2,W3,W4\n",
    "dat_w1 = np.array(df['w1mpro'])\n",
    "#dat_w1= np.hstack([dat_w1,dat_w1*0.1])\n",
    "dat_w2 = np.array(df['w2mpro'])\n",
    "#dat_w2= np.hstack([dat_w2,dat_w2*0.1])\n",
    "dat_w3 = np.array(df['w3mpro'])\n",
    "#dat_w3= np.hstack([dat_w3,dat_w3*0.1])\n",
    "dat_w4 = np.array(df['w4mpro'])\n",
    "#dat_w4= np.hstack([dat_w4,dat_w4*0.1])\n",
    "#time in MJD\n",
    "mjd =  np.array(df['mjd'])\n",
    "#dat w1\n",
    "dat_fluxw1 = dat_w1\n",
    "dat_fluxw1 = Const[1]*np.power(10,-dat_w1/2.5)*1000 \n",
    "#dat w2\n",
    "dat_fluxw2 = dat_w2\n",
    "dat_fluxw2 = Const[2]*np.power(10,-dat_w2/2.5)*1000 \n",
    "#dat w3\n",
    "dat_fluxw3 = dat_w3\n",
    "dat_fluxw3 = Const[3]*np.power(10,-dat_w3/2.5)*1000 \n",
    "#print(f'{Const[1]}*{np.power(10,-dat_w3[0]/2.5)}*1000={dat_fluxw3[0]}')\n",
    "#dat w4\n",
    "dat_fluxw4 = dat_w4\n",
    "dat_fluxw4 = Const[4]*np.power(10,-dat_w4/2.5)*1000 \n",
    "dat_w1w2 = np.concatenate([dat_fluxw1,dat_fluxw2],axis=0)\n",
    "np.savetxt('w12_'+name + '.txt',dat_w1w2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
