{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 星等转换为Flux单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_181301/3363799465.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['date'][i] = t.value\n",
      "100%|██████████| 8/8 [00:00<00:00, 2702.95it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 3505.94it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 3156.43it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 3165.35it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 2556.22it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 1677.74it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 1814.31it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 3005.54it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 1310.37it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 1880.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1408.71it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 2324.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.time import Time \n",
    "namelist = ['2003MA3','2010CO1','2010DG77','2010EX11','2010FC81','2010FH81','2010GS7','2010JN71','2010KX7','2010PW58','2010XP69','2019DD2']\n",
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    rawdata = pd.read_csv(f'{name}.csv')\n",
    "    data = rawdata.loc[:,['mjd','w1mpro','w2mpro','w3mpro','w4mpro','ph_qual','sso_flg']]\n",
    "    data.insert(loc=len(data.columns),column='date',value='no')\n",
    "    #data['mjd'] = 2400000.5+data['mjd']\n",
    "    for i in tqdm(range(len(data))):  \n",
    "        t = Time(data['mjd'][i],format='mjd',scale='utc')\n",
    "        t.format = 'iso'\n",
    "        data['date'][i] = t.value\n",
    "    #data.to_csv(f'{name}.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    rawdata = pd.read_csv(f'{name}.csv')\n",
    "    data = rawdata.loc[:,['mjd','w1mpro','w2mpro','w3mpro','w4mpro','ph_qual','sso_flg']]\n",
    "    for x in data.index:\n",
    "        if data.loc[x, 'sso_flg'] ==0:\n",
    "            data.drop(x, inplace = True)\n",
    "    data.to_csv(f'New_{name}.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7561/1341410745.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PHA'][i] = 'No'\n",
      "/tmp/ipykernel_7561/1341410745.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PHA'][i] = 'Yes'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_table('mpc_final_sort.txt')\n",
    "df = df.loc[:229]\n",
    "for i in range(len(df)):\n",
    "    if df['PHA'][i]=='Potentially':\n",
    "        df['PHA'][i] = 'Yes'\n",
    "    else:\n",
    "        df['PHA'][i] = 'No'\n",
    "df = df.sort_values(by=['PHA','time','Diam'],ascending=False,ignore_index=True)\n",
    "df.to_excel('PHA.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2Flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.3650211970971*4.5331490614641154e-05*1000=9.989474890191406\n",
      "220.3650211970971*0.00019534396563982562*1000=43.04697712894518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181301/1874399844.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Fc = np.array(Fc)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_181301/1874399844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdat_fluxw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat_w3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdat_fluxw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdat_w3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{Const[1]}*{np.power(10,-dat_w3[0]/2.5)}*1000={dat_fluxw3[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;31m#dat w4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mdat_fluxw4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat_w4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#-------initial para-------------------------\n",
    "#Fv0 of W1 ,W2, W3, W4\n",
    "Fv0 = [-1,306.682,170.663,29.045,8.284]\n",
    "#Color corrections  Col[Bv=1:8=(100,141,200,283,400,566,800,1131),fc=1:4=(W1,W2,W3,W4)]\n",
    "Fc0 = np.zeros((1,8))#W1,W2,W3,W4\n",
    "Fc1 = np.array([-1,17.2062,3.9096,2.6588,1.0032]) #Bv=100\n",
    "Fc2 = np.array([-1,4.0882,1.9739,1.4002,0.9852])  #Bv=141\n",
    "Fc3 = np.array([-1,2.0577,1.3448,1.0006,0.9833])  #Bv=200\n",
    "Fc4 = np.array([-1,1.3917,1.1124,0.8791,0.9865])  #Bv=283\n",
    "Fc5 = np.array([-1,1.1316,1.0229,0.8622,0.9903])  #Bv=400\n",
    "Fc6 = np.array([-1,1.0263,0.9919,0.8833,0.9935])  #Bv=566\n",
    "Fc7 = np.array([-1,0.9884,0.9853,0.9125,0.9958])  #Bv=800\n",
    "Fc8 = np.array([-1,0.9801,0.9877,0.9386,0.9975])  #Bv=1131\n",
    "Fc = [Fc0,Fc1,Fc2,Fc3,Fc4,Fc5,Fc6,Fc7,Fc8]\n",
    "Fc = np.array(Fc)\n",
    "Bv = 4\n",
    "Const = np.array([-1,Fv0[1]/Fc[Bv][1],Fv0[2]/Fc[Bv][2],Fv0[3]/Fc[Bv][3],Fv0[4]/Fc[Bv][4]])\n",
    "#-------read file----------------------------\n",
    "for i in range(len(namelist)):\n",
    "    name = namelist[i].lower()\n",
    "    #df = pd.read_table(f'{name}.txt')\n",
    "    df = pd.read_table(f'New_{name}.txt')\n",
    "    #data of W1,W2,W3,W4\n",
    "    dat_w1 = np.array(df['w1mpro'])\n",
    "    #dat_w1= np.hstack([dat_w1,dat_w1*0.1])\n",
    "    dat_w2 = np.array(df['w2mpro'])\n",
    "    #dat_w2= np.hstack([dat_w2,dat_w2*0.1])\n",
    "    dat_w3 = np.array(df['w3mpro'])\n",
    "    #dat_w3= np.hstack([dat_w3,dat_w3*0.1])\n",
    "    dat_w4 = np.array(df['w4mpro'])\n",
    "    #dat_w4= np.hstack([dat_w4,dat_w4*0.1])\n",
    "    #time in MJD\n",
    "    mjd =  np.array(df['mjd'])\n",
    "    #dat w1\n",
    "    dat_fluxw1 = dat_w1\n",
    "    dat_fluxw1 = Const[1]*np.power(10,-dat_w1/2.5)*1000 \n",
    "    #dat w2\n",
    "    dat_fluxw2 = dat_w2\n",
    "    dat_fluxw2 = Const[1]*np.power(10,-dat_w2/2.5)*1000 \n",
    "    #dat w3\n",
    "    dat_fluxw3 = dat_w3\n",
    "    dat_fluxw3 = Const[1]*np.power(10,-dat_w3/2.5)*1000 \n",
    "    print(f'{Const[1]}*{np.power(10,-dat_w3[0]/2.5)}*1000={dat_fluxw3[0]}')\n",
    "    #dat w4\n",
    "    dat_fluxw4 = dat_w4\n",
    "    dat_fluxw4 = Const[1]*np.power(10,-dat_w4/2.5)*1000 \n",
    "    dat_w3w4 = np.concatenate([dat_fluxw3,dat_fluxw4],axis=0)\n",
    "    np.savetxt('w34_'+name + '.txt',dat_w3w4)\n",
    "\n",
    "x = range(len(dat_w3w4))\n",
    "y = dat_w3w4\n",
    "plt.plot(x,y,'r.',linewidth=1.2)\n",
    "#plt.errorbar(x,y,fmt=\"bo:\",yerr=y*0.1,linewidth=0.6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
