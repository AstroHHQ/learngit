{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 转换为 flux，time 等数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取该目录下的csv名字 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 ['1999 MN', '2001 JV1', '2002 NV16', '2005 EE', '2009 JL1', '2009 UX17', '2010 CB55', '2010 DX1', '2010 FB81', '2010 FD7', '2010 FE7', '2010 FG81', '2010 GT6', '2010 HW81', '2010 KA8', '2010 PP58', '2011 BT15', '2014 BR8', '2014 OA2', '2014 VG2', '2014 VL6', '2015 PK57', '2015 VB65', '2015 YX7', '2016 AZ8', '2016 EV1', '2016 FO12', '2016 KD', '2016 LF2', '2016 PG67', '2016 RM40', '2016 UZ25', '2017 EL4', '2017 ER13', '2017 KR27', '2017 UC3', '2017 WK14', '2018 EC9', '2019 WV4']\n",
      "['1999MN', '2001JV1', '2002NV16', '2005EE', '2009JL1', '2009UX17', '2010CB55', '2010DX1', '2010FB81', '2010FD7', '2010FE7', '2010FG81', '2010GT6', '2010HW81', '2010KA8', '2010PP58', '2011BT15', '2014BR8', '2014OA2', '2014VG2', '2014VL6', '2015PK57', '2015VB65', '2015YX7', '2016AZ8', '2016EV1', '2016FO12', '2016KD', '2016LF2', '2016PG67', '2016RM40', '2016UZ25', '2017EL4', '2017ER13', '2017KR27', '2017UC3', '2017WK14', '2018EC9', '2019WV4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.time import Time \n",
    "path = './wisecsv'\n",
    "files = os.listdir(path)\n",
    "names = []\n",
    "for file in files:\n",
    "    if  os.path.isdir(file):\n",
    "       continue\n",
    "    names.append(file[:-4])\n",
    "names.sort()\n",
    "print(len(names),names)\n",
    "namesfinal = []\n",
    "for i in names:\n",
    "    namesfinal.append(i[:4]+i[5:])\n",
    "print(namesfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_3915379/488671845.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbjd'][i] = t.tdb.jd\n",
      "/tmp/ipykernel_3915379/488671845.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbmjd'][i] = t.tdb.mjd\n",
      "100%|██████████| 7/7 [00:00<00:00, 40.28it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1373.64it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1335.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1080.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 872.72it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1211.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1128.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1028.82it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 940.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 917.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1064.61it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 1198.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 963.69it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1092.27it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 971.54it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1072.78it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 669.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 897.43it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1273.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1134.62it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1203.23it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 954.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 942.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 901.96it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 893.19it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 999.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 696.27it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 852.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 452.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 837.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 877.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 827.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 977.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 807.89it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1062.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1129.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 986.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 867.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 864.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for ni in range(len(names)):\n",
    "    name = names[ni]\n",
    "    lis = []\n",
    "    rawdata = pd.read_csv(f'./wisecsv/{name}.csv')\n",
    "    rawdata = rawdata.loc[:,['mjd','w1mpro','w1sigmpro','w2mpro','w2sigmpro','w3mpro','w3sigmpro','w4mpro','w4sigmpro','ph_qual','sso_flg']]\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbjd',value='no')\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbmjd',value='no')\n",
    "    #rawdata['mjd'] = 2400000.5+rawdata['mjd']\n",
    "    for i in tqdm(range(len(rawdata))):  \n",
    "        t = Time(rawdata['mjd'][i],format='mjd',scale='utc')\n",
    "        t.format = 'iso'\n",
    "        rawdata['tdbjd'][i] = t.tdb.jd\n",
    "        rawdata['tdbmjd'][i] = t.tdb.mjd\n",
    "        lis.append(t.tdb.jd)\n",
    "    lis = np.array(lis)\n",
    "    np.savetxt(f'./datjd/mba.jd.{namesfinal[ni]}',lis,fmt = '%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据个数大于5 的拿出来用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_3915379/1334396244.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbjd'][i] = t.tdb.jd\n",
      "/tmp/ipykernel_3915379/1334396244.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbmjd'][i] = t.tdb.mjd\n",
      "100%|██████████| 7/7 [00:00<00:00, 864.17it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 990.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 885.62it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1460.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1087.34it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1244.16it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 970.88it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 1197.50it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1340.95it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1325.28it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1290.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1356.41it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1193.65it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1001.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1201.94it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1435.15it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 917.31it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 1362.88it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1034.52it/s]\n"
     ]
    }
   ],
   "source": [
    "names5 = []\n",
    "newnames = []\n",
    "for ni in range(len(names)):\n",
    "    name = names[ni]\n",
    "    lis = []\n",
    "    rawdata = pd.read_csv(f'./wisecsv/{name}.csv')\n",
    "    if len(rawdata)<5:\n",
    "        continue\n",
    "    names5.append(namesfinal[ni])\n",
    "    newnames.append(name)\n",
    "    rawdata = rawdata.loc[:,['mjd','w1mpro','w1sigmpro','w2mpro','w2sigmpro','w3mpro','w3sigmpro','w4mpro','w4sigmpro','ph_qual','sso_flg']]\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbjd',value='no')\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbmjd',value='no')\n",
    "    #rawdata['mjd'] = 2400000.5+rawdata['mjd']\n",
    "    for i in tqdm(range(len(rawdata))):  \n",
    "        t = Time(rawdata['mjd'][i],format='mjd',scale='utc')\n",
    "        t.format = 'iso'\n",
    "        rawdata['tdbjd'][i] = t.tdb.jd\n",
    "        rawdata['tdbmjd'][i] = t.tdb.mjd\n",
    "        lis.append(t.tdb.jd)\n",
    "    lis = np.array(lis)\n",
    "    np.savetxt(f'./datjd5/mba.jd.{namesfinal[ni]}',lis,fmt = '%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成wise统计列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>D_wise</th>\n",
       "      <th>Hv_wise</th>\n",
       "      <th>PS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999 MN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001 JV1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002 NV16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  D_wise  Hv_wise  PS\n",
       "0    1999 MN       0        0   0\n",
       "1   2001 JV1       0        0   0\n",
       "2  2002 NV16       0        0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name':newnames})\n",
    "df.insert(loc=1,column='D_wise',value=0)\n",
    "df.insert(loc=2,column='Hv_wise',value=0)\n",
    "df.insert(loc=3,column='PS',value=0)\n",
    "#df.to_excel('wise_D.xlsx')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成 JPL 文件 jpl_orb.dat.{name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n5 = np.array(names5)\n",
    "np.savetxt('name.txt',n5,fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999MN\n",
      "2001JV1\n",
      "2002NV16\n",
      "2009UX17\n",
      "2010CB55\n",
      "2010DX1\n",
      "2010FB81\n",
      "2010FG81\n",
      "2010HW81\n",
      "2010KA8\n",
      "2010PP58\n",
      "2011BT15\n",
      "2014OA2\n",
      "2014VL6\n",
      "2015YX7\n",
      "2016AZ8\n",
      "2016EV1\n",
      "2016KD\n",
      "2017KR27\n"
     ]
    }
   ],
   "source": [
    "for i in names5:\n",
    "    print(i)\n",
    "    #with open(f'./datjpl/jpl_orb.dat.{i}','a') as f:\n",
    "    #    f.write(i+'\\n2451544.50D0')    \n",
    "    #f.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E 2 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in names5:\n",
    "    with open(f'./datjpl/jpl_orb.dat.{i}','r') as f :\n",
    "        data = f.read()\n",
    "    str1 = data[:20]\n",
    "    str2 = data[20:].replace('E','D')\n",
    "    #print(i,':',str2)\n",
    "    f.close()\n",
    "    with open(f'./datjpl/jpl_orb.dat.{i}','w') as f:\n",
    "        f.write(str1+str2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3915379/3900039758.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Fc = np.array(Fc)\n"
     ]
    }
   ],
   "source": [
    "#-------initial para-------------------------\n",
    "#Fv0 of W1 ,W2, W3, W4\n",
    "Fv0 = [-1,306.682,170.663,29.045,8.284]\n",
    "#Color corrections  Col[Bv=1:8=(100,141,200,283,400,566,800,1131),fc=1:4=(W1,W2,W3,W4)]\n",
    "Fc0 = np.zeros((1,8))#W1,W2,W3,W4\n",
    "Fc1 = np.array([-1,17.2062,3.9096,2.6588,1.0032]) #Bv=100\n",
    "Fc2 = np.array([-1,4.0882,1.9739,1.4002,0.9852])  #Bv=141\n",
    "Fc3 = np.array([-1,2.0577,1.3448,1.0006,0.9833])  #Bv=200\n",
    "Fc4 = np.array([-1,1.3917,1.1124,0.8791,0.9865])  #Bv=283\n",
    "Fc5 = np.array([-1,1.1316,1.0229,0.8622,0.9903])  #Bv=400\n",
    "Fc6 = np.array([-1,1.0263,0.9919,0.8833,0.9935])  #Bv=566\n",
    "Fc7 = np.array([-1,0.9884,0.9853,0.9125,0.9958])  #Bv=800\n",
    "Fc8 = np.array([-1,0.9801,0.9877,0.9386,0.9975])  #Bv=1131\n",
    "Fc = [Fc0,Fc1,Fc2,Fc3,Fc4,Fc5,Fc6,Fc7,Fc8]\n",
    "Fc = np.array(Fc)\n",
    "Bv = 4\n",
    "Const = np.array([-1,Fv0[1],Fv0[2],Fv0[3],Fv0[4]])\n",
    "def h2flux(Fconst,dat_H):\n",
    "    return Fconst*np.power(10,-dat_H/2.5)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_3915379/4125950680.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbjd'][i] = t.tdb.jd\n",
      "/tmp/ipykernel_3915379/4125950680.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawdata['tdbmjd'][i] = t.tdb.mjd\n",
      "100%|██████████| 7/7 [00:00<00:00, 1213.98it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1470.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1111.43it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 1654.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1601.92it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1183.63it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 1383.66it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 1465.52it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1245.13it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1090.14it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1190.94it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1473.44it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1449.67it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1462.58it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1272.08it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1264.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 790.72it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 1416.97it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1106.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names5)):\n",
    "    namei = names5[i]\n",
    "    filename = namei[:4]+' '+namei[4:]\n",
    "    rawdata = pd.read_csv(f'./wisecsv/{filename}.csv')\n",
    "    rawdata = rawdata.loc[:,['mjd','w1mpro','w1sigmpro','w2mpro','w2sigmpro','w3mpro','w3sigmpro','w4mpro','w4sigmpro','ph_qual','sso_flg']]\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbjd',value='no')\n",
    "    rawdata.insert(loc=len(rawdata.columns),column='tdbmjd',value='no')\n",
    "    #rawdata['mjd'] = 2400000.5+rawdata['mjd']\n",
    "    for i in tqdm(range(len(rawdata))):  \n",
    "        t = Time(rawdata['mjd'][i],format='mjd',scale='utc')\n",
    "        t.format = 'iso'\n",
    "        rawdata['tdbjd'][i] = t.tdb.jd\n",
    "        rawdata['tdbmjd'][i] = t.tdb.mjd\n",
    "    rawdata\n",
    "    data = rawdata.loc[:,['tdbjd','w1mpro','w1sigmpro','w2mpro','w2sigmpro','w3mpro','w3sigmpro','w4mpro','w4sigmpro']]\n",
    "    data1234 = data.loc[:,['w1mpro','w1sigmpro','w2mpro','w2sigmpro','w3mpro','w3sigmpro','w4mpro','w4sigmpro']]\n",
    "    data1234.insert(loc=len(data1234.columns),column='w1nan',value=0)\n",
    "    data1234.insert(loc=len(data1234.columns),column='w2nan',value=0)\n",
    "    data1234.insert(loc=len(data1234.columns),column='w3nan',value=0)\n",
    "    data1234.insert(loc=len(data1234.columns),column='w4nan',value=0)      \n",
    "    for i in range(len(data1234)):\n",
    "        if data1234.loc[i,'w1sigmpro']>0:\n",
    "            data1234.loc[i,'w1nan'] = 1\n",
    "        else:\n",
    "            data1234.loc[i,'w1sigmpro'] = 0.01\n",
    "        if data1234.loc[i,'w2sigmpro']>0:\n",
    "            data1234.loc[i,'w2nan'] = 1\n",
    "        else:\n",
    "            data1234.loc[i,'w2sigmpro'] = 0.01\n",
    "        if data1234.loc[i,'w3sigmpro']>0:\n",
    "            data1234.loc[i,'w3nan'] = 1\n",
    "        else:\n",
    "            data1234.loc[i,'w3sigmpro'] = 0.01\n",
    "        if data1234.loc[i,'w4sigmpro']>0:\n",
    "            data1234.loc[i,'w4nan'] = 1\n",
    "        else:\n",
    "            data1234.loc[i,'w4sigmpro'] = 0.01\n",
    "    datafill = data1234.fillna(method='ffill',axis=1).fillna(method='backfill',axis=1)\n",
    "    #data of W1,W2,W3,W4\n",
    "    dat_w1 = np.array(datafill['w1mpro'])\n",
    "    #dat_w1= np.hstack([dat_w1,dat_w1*0.1])\n",
    "    dat_w2 = np.array(datafill['w2mpro'])\n",
    "    #dat_w2= np.hstack([dat_w2,dat_w2*0.1])\n",
    "    dat_w3 = np.array(datafill['w3mpro'])\n",
    "    #dat_w3= np.hstack([dat_w3,dat_w3*0.1])\n",
    "    dat_w4 = np.array(datafill['w4mpro'])\n",
    "    #dat_w4= np.hstack([dat_w4,dat_w4*0.1])\n",
    "    #dat w1\n",
    "    dat_fluxw1 = dat_w1\n",
    "    dat_fluxw1 = Const[1]*np.power(10,-dat_w1/2.5)*1000 \n",
    "    #dat w2\n",
    "    dat_fluxw2 = dat_w2\n",
    "    dat_fluxw2 = Const[2]*np.power(10,-dat_w2/2.5)*1000 \n",
    "    #dat w3\n",
    "    dat_fluxw3 = dat_w3\n",
    "    dat_fluxw3 = Const[3]*np.power(10,-dat_w3/2.5)*1000 \n",
    "    #print(f'{Const[1]}*{np.power(10,-dat_w3[0]/2.5)}*1000={dat_fluxw3[0]}')\n",
    "    #dat w4\n",
    "    dat_fluxw4 = dat_w4\n",
    "    dat_fluxw4 = Const[4]*np.power(10,-dat_w4/2.5)*1000 \n",
    "    dat234 = np.concatenate([dat_fluxw2,dat_fluxw3,dat_fluxw4],axis=0)\n",
    "    #np.savetxt(f'obs.txt.{name}',dat234)\n",
    "    dat1234 = np.concatenate([dat_fluxw1,dat_fluxw2,dat_fluxw3,dat_fluxw4],axis=0)\n",
    "    #np.savetxt(f'obsNEW.txt.{name}',dat1234)\n",
    "    dat_err1 = np.array(datafill['w1sigmpro'])\n",
    "    err1 = dat_err1\n",
    "    err1 = Const[1]*(-1/2.5)*np.power(10,(-1/2.5)*(dat_w1-1))*1000*dat_err1\n",
    "    err1 = abs(err1)\n",
    "    dat_err2 = np.array(datafill['w2sigmpro'])\n",
    "    err2 = dat_err2\n",
    "    err2 = Const[2]*(-1/2.5)*np.power(10,(-1/2.5)*(dat_w2-1))*1000*dat_err2\n",
    "    err2 = abs(err2)\n",
    "    dat_err3 = np.array(datafill['w3sigmpro'])\n",
    "    err3 = dat_err3\n",
    "    err3 = Const[3]*(-1/2.5)*np.power(10,(-1/2.5)*(dat_w3-1))*1000*dat_err3\n",
    "    err3 = abs(err3)\n",
    "    dat_err4 = np.array(datafill['w1sigmpro'])\n",
    "    err4 = dat_err4\n",
    "    err4 = Const[4]*(-1/2.5)*np.power(10,(-1/2.5)*(dat_w4-1))*1000*dat_err4\n",
    "    err4 = abs(err4)\n",
    "    daterr = np.concatenate([err1,err2,err3,err4],axis=0)\n",
    "    np.savetxt(f'./datflux/obsNEWerr.txt.{namei}',daterr)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
